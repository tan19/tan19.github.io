%!TEX root = ../MachineLearning2.tex

\chapter{Q \& A}
\ques{
    What is curse of dimensionality?
}

\ans{
The curse of dimensionality is that when the dimensionality increases, the volume of the space increases so fast that the available data become sparse. This sparsity is problematic for any method that requires statistical significance. In order to obtain a statistically sound and reliable result, the amount of data needed to support the result often grows exponentially with the dimensionality. Also, organizing and searching data often relies on detecting areas where objects form groups with similar properties; in high dimensional data, however, all objects appear to be sparse and dissimilar in many ways, which prevents common data organization strategies from being efficient.
}

\ques{
    Why over-fitted polynomial models (without regularization) tend to have larger coefficients?
}
\ans{
	Because coefficients essentially are measures of ``derivatives'' of different orders, the larger the coefficients, the larger the derivatives, hence the more the function changes.
}

\ques{
    What is bias-variance trade-off, and its solution?
}

\ans{
\begin{align}
	E[(y - \hat f)^2] = [Bias(\hat f)]^2 + Var(\hat f) + \sigma^2
\end{align}
where $Bias(\hat f) = E[\hat f - f]$ and $Var(\hat f) = E[(\hat f - E(\hat f))^2] = E[\hat f^2] - (E[\hat f])^2$.

One way of resolving the trade-off is to use mixture models and ensemble learning. For example, boosting combines many ``weak'' (high bias) models in an ensemble that has lower bias than the individual models, while bagging combines ``strong'' learners in a way that reduces their variance.
}

\ques{
    What are parametric models, non-parametric models, and etc.?
}

\ans{
A {\bf{parametric model}} $\mathcal{M}$ is a collection of probability distributions $P_\btheta$, each of which is described by a {\em{finite dimensional}} (vector) parameter $\btheta$. A parametric model is called identifiable if the mapping $\btheta \to P_\btheta$ is invertible.

\begin{align}
    \mathcal{M} = \{P_\btheta | \btheta \in \mathbf{\Theta} \subset \mathbb{R}^k\}
\end{align}

A {\bf{non-parametric model}} may refer to two interpretations: 1) it may refer to models that do not rely on data belonging to any particular distribution\footnote{Distribution-free methods are such examples, but they are not equivalent concepts.}, but reply on comparative properties (statistics) of the data, or population, such as the ``order statistics'', or 2) it may refer to models that do not assume the structure of a model is fixed, i.e., the model grows in size to accommodate the complexity of the data. In these techniques, individual variables are typically assumed to belong to parametric distributions, and assumptions about the types of connections among variables are also made.
}

\ques{
    What are generative models, discriminative models?
}

\ans{
For a supervised learning problem in which we wish to approximate an unknown target function $f: \XX \to \YY$, or equivalently $P(Y|X)$, one approach is to model $P(Y|X)$ directly, which is called a discriminative model; another approach is to model $P(X,Y)$, or equivalently $P(Y)$ and $P(X|Y)$, and then use the Bayes' rule, to obtain $P(Y|X)$ for each $X = x$ query.
}

\ques{
    What are log-linear models?
}

\ans{{
Such models have many names, including maximum-entropy models, exponential models, and Gibbs models;
Markov random fields are structured log-linear models, conditional random fields are Markov Random Fields with a specific training criterion.
}

\ques{
	Bayesian v.s. Frequentism?
}

\ans{
There are two main schools of statistical inference: Frequentist and Bayesian\footnote{Another being Fiducial inference, or Fisherian inference.}. The controversies arise when it comes to how to interpret the randomness of data point generating process.

Bayesians consider parameters to be \emph{random}, and the observed data are conditioned on a realization of such random variables. Notice the natural hierarchical structure in this interpretation. The goal is to inference $p(\btheta \vert D_{\btheta_0})$, where $\btheta$ are the parameters and $D_{\btheta_0}$ the observed data set conditioned on realized values $\btheta_0$ of $\btheta$. Frequentists consider parameters to be \emph{unknown but fixed}, and the observed data set is just a sample from the population. As in \cite{Efron 1978}, Efron said ``... Bayesian averages involve only the data value $\bar x$ actually seen, rather than a collection of theoretically possible other $\bar x$ values.''

Also, as answered by Michael Hochster in \cite{Hochster} and \cite{wiki}: Suppose $h$ is the unknown constant, and $H$ is the statistic computed from a sample. For Frequentists, it is valid to write $P(L \le h \le U) = 95\%$ or $P(70 \le H \le 74) = 95\%$, but not $P(70 \le h \le 74) = 95\%$ (this is $0$ or $1$). So the correct way to say is either ``if the same experiment procedure is repeated 100 times, 95 times of the CIs will cover the unknown true value $h$'', or ``before the experiment, the probability is 95\% that the CI to be obtained will cover $h$''.

Wasserman said in \cite{Wasserman} that the two schools of inference differ in their \emph{goals}, not the \emph{methods}: the goal of Frequentist inference is to construct procedures with frequency guarantees, and the goal of Bayesian inference is to quantify and manipulate degrees of beliefs.

Further Readings: Stein's example, Likelihood principle \cite{bayesian-inference advantage}, \cite{bayesian-inference likelihood}, \cite{quora CI}, \cite{quora diff}.
}

\ques{
	What are Learning, Machine Learning, Data Mining, Statistics, and their differences?
}

\ans{
Learning is a process of improving performance with experience. There are two main types of learning: deductive learning and inductive learning. Deductive learning learns to apply generalization concepts (rules) to examples; inductive learning learns to generalized concepts (rules) from examples.

Machine Learning is an example of inductive learning of machines (computers).

A big difference between Machine Learning and Data Mining is Reinforcement Learning. While one of the main goals of statistics is hypothesis testing, one of the main goals of data mining is the construction of hypotheses.
}

\ques{
	What is the difference between learning and inference?
}

\ans{
Inference reasons about unknown probability distributions; (parameter) learning is finding point estimates of quantities in the model. In Statistics, no distinction between learning and inference only inference (or estimation); and in Bayesian Statistics, all
quantities are probability distributions, so there is only the problem of inference. Inference in the Machine Learning community also includes making predictions.

So your inference algorithm gives you posteriors in functional forms, and learning algorithm estimates parameter values from data, and you then inference about predictions using the fitted model.
}
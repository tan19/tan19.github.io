\documentclass{article}
\input{/Users/tan19/Dropbox/LaTeXMacros.tex}

\newcommand{\dual}[2]{{#1}^{(#2)}} % color emphasize

\title{Notes on Markov Chain Monte Carlo Methods}
\author{Xi Tan (xtan3.1415926@gmail.com)}
\date{\today}

\begin{document}
\maketitle
\tableofcontents


\section{Introduction}
This note is based on Peter Orbanz's BNP notes:
\vspace*{5mm}
\\
\url{http://people.stat.sc.edu/hansont/stat740/MCMC.pdf}

\section{Notation}
Bold upper case letters represent matrices, e.g., $\X, \Y, \Z, \bTheta$. Bold lower case letters represent vector-valued random variables and their realizations (we do not distinguish between the two), e.g., $\x, \y, \z, \btheta$. Curly upper case letters represent spaces (i.e., possible values) of random variables, e.g., $\XX, \YY, \ZZ, \Theta$.

\section{Introduction}
Markov chain Monte Carlo (MCMC) methods can be used to draw random samples from a target distribution $p$. It is particularly useful in Bayesian data analysis, due to the difficulties of evaluating the denominator in the Bayes' formula, a.k.a. the partition function.

\begin{enumerate}
\item A discrete-time, discrete-space Markov chain is $\dual{X}{0}, \dual{X}{1}, \dots$ where $\dual{X}{t}$ obeys the Markov property that
\begin{align}
P\left[\dual{X}{t} \bigg| \dual{x}{0},\dots,\dual{x}{t-1}\right] = P\left[\dual{X}{t} \bigg| \dual{x}{t-1} \right]
\end{align}
\item A Markov chain is {\em{irreducible}} if any state $j$ can be reached from any state $i$ in a finite number of steps for all $i$ and $j$.
\item A Markov chain is {\em{periodic}} if it can visit certain portions of the state space only at regularly spaced intervals.
\end{enumerate}

The MCMC sampling strategy is to construct an irreducible, aperiodic Markov chain for which the stationary distribution equals the target distribution $p$.

Suppose we want to draw samples from $p(x)$. The M-H algorithm proceeds as follows: Draw a candidate state, $x^*$, according to the proposal distribution $g(x^*|x)$, by computing the acceptance probability
\begin{align}
\alpha(x^*, x) = \min\left[1, a(x^*,x) = \frac{p(x^*)g(x|x^*)}{p(x)g(x^*|x)}\right].
\end{align}
where $a(x^*,x)$ is called the M-H ratio, and $\alpha(x^*,x)$ the probability of move. With {\em{probability of move}} $\alpha(x^*, x)$, set the new state, $x'$ to $x^*$. Otherwise, let $x'$ be the same as $x$. The intuition behind the probability of move is that, if the detailed balance condition is satisfied: $p(x)g(x^*|x) = p(x^*)g(x|x^*)$, then we are done, otherwise, the denominator $g(x^*|x)p(x)$ is proportional to the probability of moving from $x$ to $x^*$, if it is large then the numerator, which is proportional to the probability of moving from $x^*$ to $x$, then we should penalize it.

The sampled sequence may contain duplicated copies of data points, the frequency of which is used to correct the difference between the proposal distribution and the target one. A well chosen proposal distribution produces candidate values that efficiently cover the support of the target distribution.

\section{Independence Chains}
If we choose the proposal distribution to be
\begin{align}
g(x^*|x) = g(x^*)
\end{align}
then the M-H ratio is
\begin{align}
a(x^*, x) = \frac{p(x^*)g(x)}{p(x)g(x^*)}.
\end{align}

For example, in a Bayesian framework, if the target distribution is the posterior $p(\theta|\y)$, where $\y$ is the data. Then, if we choose the proposal distribution to be the prior $p(\theta)$
\begin{align}
g(\theta^*|\theta) = p(\theta^*)
\end{align}
then the M-H ratio is
\begin{align}
a(\theta^*, \theta | \y) &= \frac{p(\theta^*|\y)p(\theta)}{p(\theta|\y)p(\theta^*)} = \frac{p(\y|\theta^*)p(\theta^*)/p(\y)}{p(\y|\theta)p(\theta)/p(\y)}\frac{p(\theta)}{p(\theta^*)} = \frac{p(\y|\theta^*)}{p(\y|\theta)}
\end{align}
So if the proposal distribution is the prior, the M-H ratio is the likelihood ratio.

\section{Random walk chains}
Let $x^*$ be generated by setting
\begin{align}
x^* = x + \epsilon,\quad \epsilon \sim h(\epsilon)
\end{align}
or equivalently,
\begin{align}
g(x^*|x) = h(x^* - x)
\end{align}
For example, $h$ can be the uniform, or the standard normal, or the Student's $t$ distribution.


\section{Gibbs sampler}
Suppose it is easy to sample from the univariate conditional distributions:
\begin{align}
x_i | \x_{-i} \sim f(x_i | \x_{-i})
\end{align}
then the basic Gibbs sampler can be described as follows:
\begin{enumerate}
\item Select starting values $\dual{x}{0}$ and set $t=0$.
\item Generate, in turn for $i = 1, \dots, n$:
\begin{align}
\dual{x_i}{t+1} | \x_{-i}^{(t)} \sim f\left(x_1 | \x_{-i}^{(t)}\right).
\end{align}
\item Increment $t$ and go to step 2.
\end{enumerate}
A hybrid MCMC may contain different types of samplers. For example, The M-H within Gibbs algorithm is typically useful when the univariate conditional density for one or more elements is not available in closed form.

\section{Test for Convergence}
\begin{enumerate}
\item Burn-in.
\item Run multiple chains, and if the within- and between-chain behaviors are similar, suggests that the chains are stationary. Gelman-Rubin statistic.
\item Plot samples against time, or log-likelihood against time.
\item Autocorrelation function (ACF) plot: lag versus correlation. Slow decay suggests poor mixing.
\item Re-parameterize the model may help.
\item Burn-in should be about $5000$ iterations, chain lengths should be about $100$ times the burn-in.
\item Standard error should be less than $5\%$ of the standard deviation.
\end{enumerate}

\section{How it is used}
Marginalization: just ignore others. Mean and variance: use samples. Probability estimates: estimated by the frequencies. Standard error of estimates: batch runs to obtain estimates and compute mean and standard error (divided by the square root of batch size). Density: kernel density or simply histogram.

\section{Advanced MCMC methods}
Slice sampling and other auxiliary variable methods, reversible jump MCMC, perfect sampling, Hit-and-run (choose a direction and then a distance to run), multi-try (choose from a set of candidates), Langevin M-H (random walk with drift) and etc.

\subsection{Slice sampling}
Introduce an auxilary varialbe $u$, and if we can sample from $f(x,u) = f(x)f(u|x)$ then dropping $u$ and retain $x$ as desired. The slice sampling works as follows:
\begin{align}
\dual{u}{t+1} | \dual{x}{t} &\sim \text{Unif}\left(0, f\left(\dual{x}{t}\right)\right)\\
\dual{x}{t+1} | \dual{u}{t+1} &\sim \text{Unif}\left(x: f(x) \ge \dual{u}{t+1}\right)
\end{align}
It is particularly useful for multi-modal problems (but not for high dimensional ones).

\subsection{Reversible Jump MCMC}
RJMCMC is suitable for nonparametric models where model dimensions change. The key is to use auxiliary variables to match the dimensions.

\end{document}

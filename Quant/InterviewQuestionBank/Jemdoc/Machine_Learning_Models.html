<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Models (3 Problems)</title>
<!-- Customized Scripts -->
<link rel="stylesheet" href="http://tan19.github.io/bin/jemdoc.css", type="text/css">
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End Customized Scripts -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Quant</div>
<div class="menu-item"><a href="../index.html">Go&nbsp;Up</a></div>
<div class="menu-item"><a href="http://tan19.github.io">Homepage</a></div>
<div class="menu-category">Brainteaser</div>
<div class="menu-item"><a href="../../Brainteaser.html">Introduction</a></div>
<div class="menu-item"><a href="Brainteaser_Logic_Brainteaser.html">Logic&nbsp;Brainteaser</a></div>
<div class="menu-item"><a href="Brainteaser_Math_Brainteaser.html">Math&nbsp;Brainteaser</a></div>
<div class="menu-category">Math</div>
<div class="menu-item"><a href="../../Math.html">Introduction</a></div>
<div class="menu-item"><a href="Mathematics_Combinatorics_and_Probability.html">Combinatorics&nbsp;&amp;&nbsp;Probability</a></div>
<div class="menu-item"><a href="Mathematics_Linear_Algebra.html">Linear&nbsp;Algebra</a></div>
<div class="menu-item"><a href="Mathematics_Calculus.html">Calculus</a></div>
<div class="menu-item"><a href="Mathematics_Differential_Equations.html">Differential&nbsp;Equations</a></div>
<div class="menu-category">Finance</div>
<div class="menu-item"><a href="../../Finance.html">Introduction</a></div>
<div class="menu-item"><a href="Finance_Stochastic_Calculus.html">Stochastic&nbsp;Calculus</a></div>
<div class="menu-item"><a href="*">Options&nbsp;Trading&nbsp;Strategies</a></div>
<div class="menu-item"><a href="*">Implied&nbsp;Vol&nbsp;Surface&nbsp;Fitting</a></div>
<div class="menu-item"><a href="*">Equity&nbsp;Derivatives&nbsp;Pricing</a></div>
<div class="menu-category">Computer Science</div>
<div class="menu-item"><a href="../../CS.html">Introduction</a></div>
<div class="menu-item"><a href="Computer_Science_Programming_Languages.html">Programming&nbsp;Languages</a></div>
<div class="menu-item"><a href="Computer_Science_Compiler.html">Compiler</a></div>
<div class="menu-item"><a href="Computer_Science_Database.html">Database</a></div>
<div class="menu-item"><a href="Computer_Science_Operating_System.html">Operating&nbsp;System</a></div>
<div class="menu-item"><a href="Computer_Science_Network.html">Network</a></div>
<div class="menu-item"><a href="Computer_Science_Design.html">Design</a></div>
<div class="menu-category">Algorithms and Optimization</div>
<div class="menu-item"><a href="../../Algorithm.html">Introduction</a></div>
<div class="menu-item"><a href="Algorithm_Data_Structures.html">Data&nbsp;Structures</a></div>
<div class="menu-item"><a href="Algorithm_Algorithms.html">Algorithms</a></div>
<div class="menu-item"><a href="Algorithm_Unconstrained_Optimization.html">Unconstrained&nbsp;Optimization</a></div>
<div class="menu-item"><a href="Algorithm_Constrained_Optimization.html">Constrained&nbsp;Optimization</a></div>
<div class="menu-category">Machine Learning</div>
<div class="menu-item"><a href="../../ML.html">Introduction</a></div>
<div class="menu-item"><a href="*">Mathematical&nbsp;Statistics</a></div>
<div class="menu-item"><a href="*">Linear&nbsp;Regression</a></div>
<div class="menu-item"><a href="*">Non-Linear&nbsp;Regression</a></div>
<div class="menu-item"><a href="*">Linear&nbsp;Classification</a></div>
<div class="menu-item"><a href="*">Non-Linear&nbsp;Classification</a></div>
<div class="menu-item"><a href="*">Deep&nbsp;Learning</a></div>
<div class="menu-item"><a href="Machine_Learning_Models.html" class="current">Models</a></div>
<div class="menu-category">Projects</div>
<div class="menu-item"><a href="../../LeetCode/index.html">LeetCode</a></div>
<div class="menu-item"><a href="*">Kaggle</a></div>
<div class="menu-item"><a href="*">Github</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Models (3 Problems)</h1>
<div id="subtitle"></div>
</div>
<ul>
<li><p>Machine Learning (3 Problems)</p>
</li>
</ul>
<h2>Machine Learning</h2>
<p></p>
<div class="infoblock">
<div class="blockcontent">
<p><b>Question #1: </b>
Bayesian v.s. Frequentism?

<br /><br /><b>Title: </b>Bayesian v.s. Frequentism?<br /><b>FileName: </b>6001.md<br /><b>Difficulty: </b>Easy<br /><b>Category: </b>Machine Learning/Models/Machine Learning<br /><b>Tags: </b>Naive Bayes; Logistic Regression<br /><b>Source: </b>NA<br /></p>
</div></div>
<p><b>Answer: </b>
There are two main schools of statistical inference: Frequentist and Bayesianfootnote{Another being Fiducial inference, or Fisherian inference.}. The controversies arise when it comes to how to interpret the randomness of data point generating process.

Bayesians consider parameters to be emph{random}, and the observed data are conditioned on a realization of such random variables. Notice the natural hierarchical structure in this interpretation. The goal is to inference \(p(\theta \vert D_{\theta_0})\), where \(\theta\) are the parameters and \(D_{\theta_0}\) the observed data set conditioned on realized values \(\theta_0\) of \(\theta\). Frequentists consider parameters to be emph{unknown but fixed}, and the observed data set is just a sample from the population. Efron said &ldquo;&hellip; Bayesian averages involve only the data value \(\bar x\) actually seen, rather than a collection of theoretically possible other \(\bar x\) values.&rdquo;

Also, as answered by Michael Hochster: Suppose \(h\) is the unknown constant, and \(H\) is the statistic computed from a sample. For Frequentists, it is valid to write \(P(L \le h \le U) = 95\<tt>\) or \(P(70 \le H \le 74) = 95\</tt>\), but not \(P(70 \le h \le 74) = 95\%\) (this is \(0\) or \(1\)). So the correct way to say is either &ldquo;if the same experiment procedure is repeated 100 times, 95 times of the CIs will cover the unknown true value \(h\)&rdquo;, or &ldquo;before the experiment, the probability is 95% that the CI to be obtained will cover \(h\)&rdquo;.

Wasserman said that the two schools of inference differ in their emph{goals}, not the emph{methods}: the goal of Frequentist inference is to construct procedures with frequency guarantees, and the goal of Bayesian inference is to quantify and manipulate degrees of beliefs.
</p>
<div class="infoblock">
<div class="blockcontent">
<p><b>Question #2: </b>
Explain Kalman Filter.

<br /><br /><b>Title: </b>Kalman Filter<br /><b>FileName: </b>6002.md<br /><b>Difficulty: </b>Easy<br /><b>Category: </b>Machine Learning/Models/Machine Learning<br /><b>Tags: </b>Kalman Filter<br /><b>Source: </b>NA<br /></p>
</div></div>
<p><b>Answer: </b>

</p>
<div class="infoblock">
<div class="blockcontent">
<p><b>Question #3: </b>
Compare <b></b>Naive Bayes<b></b> and <b></b>Logistic Regression<b></b>.

<br /><br /><b>Title: </b>Naive Bayes vs Logistic Regression<br /><b>FileName: </b>6003.md<br /><b>Difficulty: </b>Easy<br /><b>Category: </b>Machine Learning/Models/Machine Learning<br /><b>Tags: </b>Naive Bayes; Logistic Regression<br /><b>Source: </b>NA<br /></p>
</div></div>
<p><b>Answer: </b>
NB has high bias as it focuses on a smaller set of models, converges faster but error rate may be high if assumptions are incorrect. Logistic Regression has lower bias as it allows a larger model space, converges to solutions slower but error rate can be lower due to low bias. Logistic Regression tends to be used a LOT more in industry but if your prior information is accurate (data is generated from a well known process), NB may be a better choice.

NB assumes that the input features are conditional  independent. NB also requires a prior distribution. Simple LR cannot do nonlinear classification.
</p>
<div id="footer">
<div id="footer-text">
Page generated 2021-05-07 17:24:59 Eastern Daylight Time, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>

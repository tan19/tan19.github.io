\section{Probaility Space}
\section{Sample Space, Events, and Probability}
\begin{deff}
	A sample space $S$ is a set of all possible outcomes of an experiment. An outcome is also called a sample point.
\end{deff}
Note, when an experiment consists of several repetitions, each one of them is called a {\em{trial}}. As an example, if one decides to toss a coin 42 times, we can call each toss a trial of the experiment composed of 42 ones.

\begin{deff}
	An event $E$ is a subset of the sample space $S$. If the outcome of the experiment is contained in $E$, then we say that $E$ occurred.
\end{deff}

\begin{deff}\label{def:probability}
In short, a probability space is a measure space such that the measure of the whole space is equal to one. The expanded definition is following: a probability space is a triple $(\Omega,\; \mathcal{F},\; P)$ consisting of:
\begin{itemize}
\item the sample space $\Omega$ --- an arbitrary non-empty set,
\item the $\sigma-algebra$ $\FF \in 2^\Omega$ (also called $\sigma-filed$) --- a set of subsets of $\Omega$, called events, such that:
	\begin{itemize}
	\item $\FF$ contains the empty set: $\emptyset \in \FF$,
	\item $\FF$ is closed under complements: if $A \in \FF$, then also $(\Omega \setminus A) \in \FF$,
	\item $\FF$ is closed under countable unions: if $A_i \in \FF$ for $i=1,2,\ldots$, then also ($\bigcup A_i) \in \FF$,
	\end{itemize}
\item the probability measure $P: \FF \rightarrow [0,1]$ --- a function on $\FF$ such that:
\item $P$ is countably additive: if $\{A_i\} \in \FF$ is a countable collection of pairwise disjoint sets, then $P(\bigcup A_i) = \sum P(A_i)$, where $\bigcup$ denotes the disjoint union,
\item the measure of entire sample space is equal to one: $P(\Omega)=1$.
\end{itemize}
\end{deff}

\section{Probability Axioms}
\subsection{Law of Total Probability}
Suppose $B_n (n=1,2,3,\cdots$ is a finite or countably infinity partition of the sample space, then for an event $A$
\begin{align}
	Pr(A) = \sum_n Pr(A,B_n)
\end{align}
or,
\begin{align}\label{eq:Law of Total Probability}
	Pr(A) = \sum_n Pr(A|B_n) Pr(B_n)
\end{align}
It can also be stated for conditional probabilities. Suppose $X$ is an event in the same sample space, we have
\begin{align}
	Pr(A|X) = \sum_n Pr(A|B_n,X)Pr(B_n|X)
\end{align}
One application of Eq~\ref{eq:Law of Total Probability} is when calculating $Pr(A)$ is difficult, we can introduce an ``auxiliary variable'' $B$, in the hope that the conditional probability $Pr(A|B_n)$ is easier to compute.
\subsection{Law of Total Variance}
\subsection{Law of Total Covariance}
\subsection{Law of Total Expectation}
\subsection{Law of Total Cumulance}
\subsection{Probability Inequalities}

\section{Types of Probabilities: Frequentism and Bayesian} 
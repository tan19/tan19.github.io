\section{Limit Theorems}
\section{Markov and Chebyshev Inequalities}
\begin{thm}
	{\underline{Markov's Inequality}}. If $X$ is a random variable that takes only nonnegative values, then for any value $a > 0$, $$P\{X \ge a\} \le \frac{E[X]}{a}$$
\end{thm}

\begin{thm}
	{\underline{Chebyshev's Inequality}}. If $X$ is a random variable with finite mean $\mu$ and variance $\sigma^2$, then, for any value $k > 0$, $$P\{|X-\mu| \ge k\} \le \frac{\sigma^2}{k^2}$$
\end{thm}

\section{Weak Law of Large Numbers}
\begin{thm}
	{\underline{The Weak Law of Large Numbers}}. Let $X_1, X_2, \cdots$ be a sequence of i.i.d. random variables, each having finite mean $E[X_i] = \mu$. Then, for any $\epsilon > 0$, $$P\left\{\left|\frac{X_1+\cdots+X_n}{n} - \mu\right| \ge \epsilon \right\} \to 0 \mbox{ as } n \to \infty$$
\end{thm}

\section{Central Limit theorem}
\begin{thm}
	{\underline{Central Limit theorem}}. Let $X_1, X_2, \cdots$ be a sequence of independent and identically distributed random variables, each having mean $\mu$ and variance $\sigma^2$. Then the distribution of $$\frac{\frac{X_1+\cdots+X_n}{n}-\mu}{\sqrt{\sigma^2/n}} = \frac{X_1+\cdots+X_n - n\mu}{\sigma \sqrt{n}}$$ tends to the standard normal as $n \to \infty$.
\end{thm} 
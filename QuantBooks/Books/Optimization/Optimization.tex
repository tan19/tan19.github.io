\documentclass{memoir}
\input{../LaTeXMacros.tex}

\title{Optimization Notes}
\author{Xi Tan (tan19@purdue.edu)}
\date{\today}

\makeindex

\begin{document}
\maketitle
\tableofcontents

\chapter{Introduction}
{\em{Quadratic optimization problems}} (including, e.g., least-squares) form the base of the hierarchy; they can be solved exactly by solving a set of linear equations. {\em{Newton's method}} is the next level in the hierarchy. In Newton's method, solving an unconstrained or equality constrained problem is reduced to solving a sequence of quadratic problems. {\em{The interior-point methods}}, which form the top level of the hierarchy, solve an inequality constrained problem by solving a sequence of unconstrained, or equality constrained, problems. Besides Newton's method, there are quasi-Newton, conjugate-gradient, bundle, cutting-plane algorithms, and etc.

Optimization problems can be broadly divided into two types: linear optimization and nonlinear optimization,  the later of which consists of unconstrained and constrained optimization problems. Obtaining necessary and sufficient conditions is one of the central problems of nonlinear optimization. The main theory is the study of Lagrange multipliers, including the Karush-Kuhn-Tucker (KKT) theorem and its extensions. However, the theory of Lagrange multipliers is far from adequate, since it does not take into account the difficulties associated with solving the equations resulting from the necessary conditions.

\deff{
	{\em{Global convergence analysis}}. The verification that a given algorithm will in fact generate a sequence that converges to a solution point.
	{\em{Local convergence analysis}} or {\em{complexity analysis}}. The rate at which the generated sequence of points converges to the solution.
}

\chapter{Linear Programming}
\section{Basic Properties of Linear Programs}
\deff{
	Let $A$ be an $m \times n$ matrix and $B$ be any {\em{nonsingular}} $m \times m$ sub-matrix made up of columns of $A$. Then, if all $n-m$ components of $x$ not associated with columns of $B$ are set equal to zero, the solution to the resulting set of equations is said to be a {\em{basic solution}} with respect to the basis $B$. The components of $x$ associated with columns of $B$ are called {\em{basic variables}}.
}

\deff{
	If one or more of the basic variables in a basic solution has value zero, that solution is said to be a {\em{degenerate basic solution}}.
}

\deff{
	A feasible solution that is also basic is said to be a {\em{basic feasible solution}}; if this solution is also a degenerate basic solution, it is called a {\em{degenerate basic feasible solution}}.
}

\thm{
	Fundamental Theorem of Linear Programming. Given a linear program in standard form. i) if there is a feasible solution, there is a basic feasible solution; ii) if there is an optimal feasible solution, there is an optimal basic feasible solution.
}


Simplex algorithm has an exponential worst-case complexity, but polynomial average-case complexity.

\chapter{Unconstrained Optimization}
\section{Univariate Problems (Bisection, Newton, Secant Methods)}
Note that, $\min(f(x)))$ can be converted to the root-finding $f'(x) = 0$ problem.

\subsection{Bisection Method}
\index{bisection method}
Suppose $g'$ is continuous on $[a_0,b_0]$ and $g'(a_0)g'(b_0) \le 0$, then the Intermediate Value Theorem implies that there exists at least one $x^*$ for which $g'(x^*) = 0$ and hence $x^*$ is a local optimum of $g$. To find this local optimum, the Bisection Method systematically halves the interval at each iteration, by checking the product of $g'$.

The updating equations are
\begin{align}
[a_{t+1},b_{t+1}] =
	\begin{cases}
		[a_t,x^{(t)}], & \mbox{if } g'(a_t)g'(x^{t}) \le 0 \\
		[x^{(t)},b_t], & \mbox{if } g'(a_t)g'(x^{t}) > 0
	\end{cases}
\end{align}
and $x^{t+1} = \frac{a_{t+1}+b_{t+1}}{2}$.

\subsection{Newton's Method}
\index{Newton's method}
Suppose $g$ twice differentiable. At iteration $t$, Newton's method approximates $g'(x^*)$ by the linear Taylor series expansion:
\begin{align}
	g'(x^*) = g'(x^{(t)}) + (x^*-x^{(t)})(g''(x^{(t)}))
\end{align}
which gives us
\begin{align}
	x^* = x - \frac{g'(x^{(t)})}{g''(x^{(t)})}
\end{align}

\subsection{The Secant Method}
\index{secant method}
Recall that the Newton's method requires the function's derivative, which is always available. The secant method approximates the derivative with difference. It works as follows:
\begin{itemize}
  \item Start with two approximations $x_0$ and $x_1$.
  \item Compute the $(k+1)$th approximation with 
  \begin{align}
    x_{k+1} & \equiv x_k - f(x_k)/\frac{f(x_k) - f(x_{k-1})}{x_k - x_{k-1}}
  \end{align}
  \item The convergence rate of the secant method is $1.618$.

\end{itemize}

\section{Quasi-Newton Methods}

\chapter{Convex Optimization}

\printindex

\end{document}







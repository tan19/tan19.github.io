# Metadata
> Title: QR Decomposition

> Difficulty: Easy

> Category: Mathematics/Linear Algebra/Matrix Decomposition

> Tags: Trace; QR Decomposition

> Source: NA

# Question
How do you use QR decomposition in linear regression?

# Answer
Recall that the normal equation 
\begin{align*}
    \bbeta = (\X^T\X)^{-1} \X^T \y
\end{align*}
involves the inverse of $\X^T\X$, which is numerically unstable when the matrix is near singular and ill-conditioned, i.e., the condition number $$\kappa(\A) = \frac{\sigma_{\max}(\A)}{\sigma_{\min}(\A)} = ||\A^{-1}| \cdot |||\A||$$ is large. Now, suppose we have a \emph{thin} QR factorization of the design matrix (usually $n \ge p$) $$\X_{n \times p} = \Q\R = [\Q_1, \Q_2]\begin{pmatrix}\R_1\\ \bZero\end{pmatrix} = \Q_1\R_1,$$ where $Q_1, Q_2$ both have orthonormal columns but with sizes $n \times p$ and $n \times (n-p)$, respectively. $\R_1$ is an upper triangular matrix with size $p \times p$.  Then since orthogonal matrices preserve the 2-norm, we have:
\begin{align*}
    &\min_\bbeta \frac12||\X\bbeta - \y||_2^2 \\
    \implies & \min_\bbeta \frac12||\Q_1\R_1\bbeta - \y||_2^2\\
    \implies & \min_\bbeta \frac12||\Q_1^T(\Q_1\R_1\bbeta - \y)||_2^2\\
    \implies & \min_\bbeta \frac12||\R_1\bbeta - \Q_1^T\y||_2^2\\		
\end{align*}
Since $\R_1$ is upper triangular, we only need one backward sweep and one forward sweep to solve $\bbeta$.
